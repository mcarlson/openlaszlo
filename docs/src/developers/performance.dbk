<chapter id="performance-tuning">
<title>Performance Monitoring and Tuning</title>
<!-- remove commented out sample code that was ignored by the build. IORIO 20 nov 2007 -->
<para>
In this chapter we'll look at various ways to detect and address sources of poor performance. You may also want to investigate the <ulink url="http://www.openlaszlo.org/wiki/CallProfiler">OpenLaszlo Wiki</ulink>, where developers discuss advanced techniques, including unofficial and unsupported tools such as the call profiler.
</para>
<para role="todo"><remark role="todo"><emphasis role="para-label">TODO: </emphasis>
size profiler stuff
</remark></para>
<para>
This chapter discusses ways to measure the performance of your Laszlo
client code and gives some tips for more efficient coding.
</para>
<para>
Be sure also to see <xref linkend="debugging"/>,  which includes explanations of many useful techniques, such as tracing, backtracing, memory leak detection and object inspection, for finding performance problems.
</para>
<para/><section><title>Time Measurement</title>
<para>
Simple timing measurements can be made using <literal>(new
Date).getTime()</literal>, which will return a millisecond time.  You
can use <literal>Debug.write</literal> or <literal>Debug.log</literal> to output
timing data.  Here is a simple framework illustrating how you can use
this to measure the cost of certain operations.  A more complete
framework is available by including <literal>utils/performance</literal>.
</para>

<example role="live-example">
   <title>Measurement Framework</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$1.lzx"/></textobject> 
   </programlisting>
</example>

<para>
Because <literal>Date.getTime</literal> is based on the real time clock,
measurements using it can be deceiving: the runtime may choose to
execute maintenance tasks during your measurement period (for
instance, garbage collection) and the operating system may share the
processor with other applications during your measurement period.  The
<literal>utils/performance</literal> library uses a slightly more
sophisticated meter that accumulates both a mean time, standard
deviation, and min and max times.  In the examples below, the meters
are presented as: <literal><replaceable>mean</replaceable> ±<replaceable>std. dev.</replaceable>
[<replaceable>minimum</replaceable>..<replaceable>maximum</replaceable>]/<replaceable>trials</replaceable></literal>.  For the purposes
of measuring the relative performance of two different techniques,
comparing the minimum times of a large number of trials is probably
the most accurate.
</para>
<para>
You will see that in both the example framework and the performance
library that we accumulate statistics in two loops: a short-term loop
to ameliorate the overhead of getting the time, and a long-term loop
to minimize the perturbation due to background or other processes.
</para>

<note><para>
Be sure to do your testing on your most difficult target.  Clients
with the Flash 6 player installed will be slower than those with the
Flash 7 player installed.  Macintosh clients will, in general, be
slower than Windows clients.  Most of the advice in this chapter holds
across all players and platforms, but by viewing the examples on the
particular client of interest, you can see exactly how important the
advice is.
</para></note>

<para/></section><section><title>JavaScript Performance</title> 
<para>
Like most programming languages, JavaScript often can express the same
algorithm in a number of different ways.  Below are some tips on
choosing the more efficient of those ways.
</para>
<para/><section><title>Variables</title>
<para/><section><title>Use local variables rather than global</title>
<para>
Local variables are faster to access than global variables, so global
variables should only be used when necessary.  In particular, watch
out for erroneously writing <literal>for (i in ...)</literal> when you
really mean <literal>for (var i in ...)</literal>; similarly, <literal>for (i =
0; i &lt; ...; i++)</literal> will be less efficient than <literal>for (var
i = 0; i &lt; ...; i++)</literal>.  [In addition you are liable to
clobber an important global variable if you forget to use the
<literal>var</literal> declaration in a <literal>for</literal> loop.]
</para>
<para>
The example below uses the performance <literal>Measurement</literal> utility to
illustrate the difference between incrementing a global variable and a
local variable.
</para>
<example role="live-example">
   <title>Globals vs. Locals</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$2.lzx"/></textobject> 
   </programlisting>
</example>

<para/></section><section><title>Cache constant global references</title>
<para>
If you need to access a global reference many times that you know will
not change, create a local reference and use that instead.
</para>

<example role="live-example">
   <title>Caching globals</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$2.lzx"/></textobject> 
   </programlisting>
</example>

<para/></section>
<!-- added following section per LPP-1048, IDs vs Names IORIO 25 sep 2007 -->
<section><title>Deep path references</title>
<para>
It's expensive to do a lot of a.b.c.d.e.f references, compared to just
one global.a reference, especially if the JavaScript code repeats the
path again and again. Avoid code that repeats paths like "foo.bar.baz.x
= 1; foo.bar.baz.y = 2;". Scripting languages like JavaScript don't have
smart optimizing compilers like C++, so if you have a lot of repeated
references to the same path, it does exactly what you tell it to again
and again and doesn't optimize the code. So
it's a good practice to load any deep path references into temporary
variables if you're going to reference them more than once in the same
function. Temporary local variables are cheap (it's a stack based VM),
so it's much better to put something in a local than repeatedly
dereferencing the same path again and again.</para>
<para>
Use short local paths when you can to wire up references between close
relatives (parent/child/sibling), but it's ok to use global ids (with
long distinct descriptive names like gFunnyLookingWidget) when you need
to reference an important widget from elsewhere in the application. It's
worth using global ids when it makes code less brittle. There's a
trade-off between making the code that references the widget dependent
on the relative path, and using global ids for unique important objects,
but as long as you give the global id a good name, it's ok to use a
global id since it makes it a lot easier to rearrange the layout of the
user interface in ways that would break the paths (and then you don't
have to come up with names for all the uninteresting intermediate
views).
</para>
<para>
It's worth judiciously using global ids to avoid having to scramble all
over the program chasing down and patching up relative paths, whenever
you change the position of a widget in the view hierarchy (which can be
often, when the GUI is in flux).
</para>
<para>
Don't use global ids in class definitions or sub-objects of classes,
because all instances of that class will end up trying to use the same
conflicting id. A good middle ground is to give the top level instance
of a class a global id if necessary (where the object is instantiated,
not in the class definition), and have the class declare relative
shortcuts into deep parts of its internal structure that need to be
referenced from other parts of the code, by putting attributes on the
class like
happycheckbox="$once{this.toppanel.emotioneditor.moodcheckboxes.happyche
ckbox}". Then objects outside can use the shortcut without knowing the
internal structure of the class, and objects deeply nested inside the
class can also go "classroot.happycheckbox" to get the checkbox
independent of its position in the hierarchy, instead of
"parent.parent.parent.parent.toppanel.emotioneditor.moodcheckboxes.happy
checkbox". Then if you rearrange your class's view hierarchy, you only
have to change the long relative path reference in one place (the $once
attribute of the class lexically containing the view).
</para>
</section>
</section><section><title>Arrays</title>
<para>
For an array <literal>A</literal>, <literal>A.push(b)</literal> is more expensive
than <literal>A[A.length] = b</literal>, which in turn is more expensive
than <literal>A[i] = b</literal> (i.e., if you already had the current
length of the array in a variable).
</para>
<para>
Allocating an array in advance, when you know how many elements it
will eventually hold, makes no difference on existing runtime
platforms, because arrays are just objects that maintain a length
field.
</para>
<para>
Note that if you do not need to know how many elements are in the array, using an object can be slightly more efficient, because it does not have to maintain the length field.
</para>
<para>
The example below illustrates the various ways of adding elements to an array.
</para>

<example role="live-example">
   <title>Adding elements to an array</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$4.lzx"/></textobject> 
   </programlisting>
</example>

<para/></section><section><title>Loops</title>
<para>
In older players, <literal>while</literal> loops are slightly more efficient than <literal>for ... in</literal> loops which are slightly more efficient than <literal>for</literal> loops.  The difference is not enough that you should contort your code, but if any will work equally well, you should choose accordingly.
</para>

<example role="live-example">
   <title>Iterating with for, for in, or while</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$5.lzx"/></textobject> 
   </programlisting>
</example>

<para/></section><section><title>Conditionals</title>
<para>
Using a cascade of <literal>if</literal> statements is slightly more efficient that using
the equivalent logical operators.  This is a bug that will be fixed in
a future release, so you should not contort your code unless
absolutely necessary.
</para>

<para role="fixme"><remark role="fixme"><emphasis role="para-label">FIXME: </emphasis>Is this really a bug?  What about <literal>switch</literal> — is this faster?</remark></para>

<example role="live-example">
   <title>Conditionals vs. logical operators</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$6.lzx"/></textobject> 
   </programlisting>
</example>

<para/></section><section><title>with</title>
<para>
The use of <literal>with</literal> does not appear to affect performance, so it is a stylistic choice.
</para>

<para role="fixme"><remark role="fixme"><emphasis role="para-label">FIXME: </emphasis>Tucker, is this true?</remark></para>


<example role="live-example">
   <title>With (this) vx. this.</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$7.lzx"/></textobject> 
   </programlisting>
</example>


<para/></section><section><title>Function calls</title>

<para>The cost of a function call is about equivalent to three assignment
statements, so modularizing your code using function calls is not
going to create a big performance penalty.  Each argument passed to a
function call is about equivalent to an additional assignment.</para>

<example role="live-example">
   <title>The cost of a function call</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$8.lzx"/></textobject> 
   </programlisting>
</example>

<para/></section><section><title>Code hoisting</title>

<para>
It's always a good idea to carefully examine <indexterm significance="preferred"><primary>inner loops</primary></indexterm><glossterm>inner loops</glossterm> (loops that
are central to an algorithm and executed many times) for expressions
that don't vary with the loop index and move them out of the loop.
This is just good standard programming practice, but it may not be
quite so obvious in an object-oriented language such as JavaScript.
</para>
<para>
The example below shows how accessing a deeply nested element of a
object hierarchy is really a constant expression that can be moved out
of a loop.
</para>

<example role="live-example">
   <title>Moving constant expressions out of a loop</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$9.lzx"/></textobject> 
   </programlisting>
</example>


<para/></section></section><section><title>Optimizing startup time</title>


<para/><section><title>Using Lazy Replication</title>
<para>If you will have more items in your list than will appear to the user,
you should use <literal>dataoption="lazy"</literal>.  In this case the
listitem will use lazy replication  and the list will
use a <indexterm><primary>LzDataSelectionManager</primary></indexterm><classname>LzDataSelectionManager</classname>, instead of a
<indexterm><primary>LzSelectionManager</primary></indexterm><classname>LzSelectionManager</classname>.  Some of the APIs for adding
and removing items will not be available, but startup time will be
significantly faster.  In general, you can modify data through the
data APIs instead of using list methods.  If you
have created your own <indexterm><primary>listitem</primary></indexterm><classname>listitem</classname> class you can use the <indexterm><primary>LzDatapath</primary></indexterm><classname>LzDatapath</classname>
<indexterm><primary>replication</primary></indexterm><sgmltag class="attribute">replication</sgmltag>
attribute.</para>

<para>In the example below, only four <indexterm><primary>textlistitem</primary></indexterm><classname>textlistitem</classname>
views are created, even though there are ten items in the dataset.</para>


<note><para>If you declare a <indexterm><primary>textlistitem</primary></indexterm><sgmltag class="element">&lt;textlistitem&gt;</sgmltag><remark role="fixme">[unknown tag]</remark>
<!--unknown tag: textlistitem-->
 with a child
<indexterm><primary>datapath</primary></indexterm><sgmltag class="element">&lt;datapath&gt;</sgmltag><remark role="fixme">[unknown tag]</remark>
<!--unknown tag: datapath-->
, you must set
<literal>datareplication="lazy"</literal> on the <indexterm><primary>datapath</primary></indexterm><sgmltag class="element">&lt;datapath&gt;</sgmltag>
element if you set <literal>dataoption="lazy"</literal> in the list.  If you
are using a <indexterm><primary>datapath</primary></indexterm><sgmltag class="attribute">datapath</sgmltag> attribute, that happens
automatically.)</para></note>

<example role="live-example">
   <title>Lazy replication increases efficiency</title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$10.lzx"/></textobject> 
   </programlisting>
</example>


<para/></section>
</section>
<section><title>Optimizing runtime performance with pooling</title>



<para>If you are creating a list from data and then change the data that
is represented by the list, you should consider
<literal>dataoption="pooling"</literal>.  Normally, when the data which is bound to a view changes, the
views are re-created. However, if you use pooling, only the data is reset— the views are not recreated.  With
the textlistitem class this technique will work effectively.  If you have
created your own listitem class you can use the
<indexterm><primary>pooling</primary></indexterm><sgmltag class="attribute">pooling</sgmltag> attribute on <indexterm><primary>datapath</primary></indexterm><classname>datapath</classname>.</para>

<note><para>If you use lazy replication as described above, pooling will
also be true.</para></note>

<example role="live-example">
   <title>Pooling views </title>
   <programlisting language="lzx">
   <textobject><textdata fileref="programs/performance-tuning-$11.lzx"/></textobject> 
   </programlisting>
</example>

<!-- Added section tags to fix docbook error IORIO 25 sep 2007 -->
<section><title>Data optimization checklist</title>
<para>
Data pooling gives you the key tool in optimizing performance issues related to XML data. The philosophy
can be stated simply: </para>
<orderedlist spacing="compact"><listitem><para>Pool replicated views.</para></listitem><listitem><para>Reduce the number of subviews in a replicated row.</para></listitem><listitem><para>Defer <indexterm><primary>init</primary></indexterm><sgmltag class="element">&lt;init&gt;</sgmltag><remark role="fixme">[unknown tag]</remark>
<!--unknown tag: init-->
 of parts of your application that aren't necessary immediately.</para></listitem></orderedlist>

<para role="fixme"><remark role="fixme"><emphasis role="para-label">FIXME: </emphasis>
- removing/redefining the default font (can link to fonts chapter).
</remark></para>
<para role="fixme"><remark role="fixme"><emphasis role="para-label">FIXME: </emphasis>
This should go in the performance chapter (how large a {} is, how large a dataset node is, and the 
recommendation to use attributes instead of child elements to decrease memory overhead).
 

 var ll = []; for (var i = 0; i &lt;20000; i++) ll[i] = {foo: i}

   

When you consider that every object is a hashtable, and that most objects have a number of attributes, 
it's probably not that unreasonable.  If you figure that a hash table needs at least two words for each entry (key, value) 
and that if you use open hashing, you never want to be more than 2/3 full, then 562 bytes works out to at most 45 attributes.  
If the hash table stores hash codes, make that 3 words per entry, and 30 attributes. 
 That doesn't count for any table or class overhead either.

  that still seems a little profligate, but   RAM is essentially free these days. 
 Or perhaps they don't have a good solution for growing an object and updating all references to it, so they want 
to allocate objects big enough that they seldom have to move.

Include a graph that shows baseline memory levels.

</remark></para>
<para role="fixme"><remark role="fixme"><emphasis role="para-label">FIXME: </emphasis>
  
   First of all, what do we consider a memory leak? If you run an application
      for a while and its memory footprint grows and never comes down to its
      original level, does that necessarily indicate a leak in our libraries? Unexpected change.
      
    

</remark></para>
<para role="fixme"><remark role="fixme"><emphasis role="para-label">FIXME: </emphasis>
Measurement is expensive.  Avoid things like getTextWidth() and for forth. Instead, use built-ins (such as ???).

For details, see Adam.
</remark></para>


<para/></section></section><section><title>Application Size</title>

<para/><section><title>Measuring Application Size</title>

<para>The developer console displays the uncompressed and gzipped size of the application.  The gzipped size is the size that will be transferred to most browser clients; it is proportional to the file transfer time.  The uncompressed size is the size that will appear in the browser cache, or if you use a tool such as <literal>curl</literal> or <literal>wget</literal> to retrieve the file.</para>

<informalfigure><mediaobject><imageobject><imagedata fileref="images/size.png"/></imageobject></mediaobject></informalfigure>

<para>The developer console also contains a link to the <indexterm significance="preferred"><primary>size profile</primary></indexterm><glossterm>size profile</glossterm> for the application.  This page displays size statistics particular to the application.  These statistics are relative to the uncompressed size of the application, not the compressed size, but they are still a useful tool in finding the "size hot spots" of your application.</para>

<para/></section><section><title>Optimizing Application Size</title>

<para>Changing embedded datasets and resources to requested datasets and resources will reduce the initial download size of the application.  If these assets are only used in some execution paths, this will also reduce the total download size of the application, for use cases that avoid these execution paths.</para>


<para/></section></section><section id="inlined-classes"><title>Inlined Classes</title>

<para>An <indexterm significance="preferred"><primary>inlined</primary></indexterm><glossterm>inlined class</glossterm> is a class that is applied to an instance when an application is compiled, rather than when the application is instantiated.  An inlined class has the same semantics as a regular class, except that the class cannot be instantiated or otherwise referred to by name in script code.  An inlined class is similar to an inline function, or a macro, in other languages.</para>

<para>If a class is only instantiated once, inlining it can reduce the size of the generated application.  This is because instead of containing two definitions, one for the class and one for its instance, the application will contain only one definition.  The compiler may be able to combine tables that are used in the class with tables that are used in the instance, to save space.</para>

<para>The <literal>&lt;?lzc?&gt;</literal> XML processor directive directs the compiler to inline a class:</para>

<informalexample role="live-example"><programlisting>
&lt;canvas&gt;
  &lt;?lzc class="c1" inline="true"?&gt;
  &lt;class name="c1"&gt;
    &lt;view name="v2"/&gt;
    &lt;view name="v3"/&gt;
  &lt;/class&gt;
  &lt;view name="v1"&gt;
    &lt;c1/&gt;
  &lt;/view&gt;
&lt;/canvas&gt;
</programlisting></informalexample>

<para>The program above compiles to the same executable as the following source code:</para>

<informalexample role="live-example"><programlisting>
&lt;canvas&gt;
  &lt;?lzc class="c1" inline="true"?&gt;
  &lt;class name="c1"&gt;
  &lt;/class&gt;
  &lt;view name="v1"&gt;
    &lt;view&gt;
      &lt;view name="v2"/&gt;
      &lt;view name="v3"/&gt;
    &lt;/view&gt;
  &lt;/view&gt;
&lt;/canvas&gt;
</programlisting></informalexample>

<para>The only difference between these programs the organization of the source code, which allows the developer to defer the decision about whether to combine the class and the instance definition, and to maintain the class definition separately, for readability and in order to easily revisit the decision if a second instance is added, for example.</para>

<para>The compiler directive has two forms.  The <indexterm><primary>class</primary></indexterm><sgmltag class="attribute">class</sgmltag> attribute is a single class.  The <indexterm><primary>classes</primary></indexterm><sgmltag class="attribute">classes</sgmltag> attribute is a list of class names, so that this</para>
<programlisting>
&lt;?lzc class="c1" inline-only="true"?&gt;
&lt;?lzc class="c2" inline-only="true"?&gt;</programlisting>
<para>can be abbreviated as this:</para>
<programlisting>
  &lt;?lzc classes="c1 c2" inline-only="true"?&gt;
</programlisting>

<para><literal>inline-only</literal> has two effects: the class definition is applied at compile time, and the runtime representation of the class is omitted from the executable file.</para>

<para>The compiler expands non-inlined class definitions that extend inlined classes, and inlined classes that extend inlined classes.</para>

<para>The following cases can't be inlined.  They will result in a compilation error.</para>
<itemizedlist spacing="compact"><listitem><para>A inlined class with an instance that defines a method with the same name as a method in the class definition.</para></listitem><listitem><para>A inlined class with an instance that defines an <literal>on<varname>event</varname></literal>code&gt; with the same name as an event that the class defines.</para></listitem><listitem><para>A inlined class that a non-inlined subclass extends.  If you inline a class, you have to inline its subclasses too.</para></listitem><listitem><para>A inlined class that contains the <indexterm><primary>defaultplacement</primary></indexterm><sgmltag class="attribute">defaultplacement</sgmltag> attribute.</para></listitem><listitem><para>An inlined class with an instance that contains a child with a <indexterm><primary>placement</primary></indexterm><sgmltag class="attribute">placement</sgmltag> attribute.</para></listitem><listitem><para>An inlined class that defines an an attribute value with a subclass or instance that defines an attribute for that attribute.</para></listitem></itemizedlist>

<para>Inlined classes make it easier to factor a program across multiple files without a performance penalty.  In the following program, a view and a resource have been moved to a separate file.</para>

<informalexample role="live-example"><programlisting>
&lt;canvas&gt;
  &lt;?lzc class="c1" inline="true"?&gt;
  &lt;include href="lib1.lzx"/&gt;
  &lt;view name="v1"&gt;
    &lt;c1/&gt;
  &lt;/view&gt;
&lt;/canvas&gt;
</programlisting></informalexample>

<example role="live-example"><title>lib1.lzx</title><programlisting>
&lt;library&gt;
  &lt;resource name="r1" src="pic1.jpg"/&gt;
  &lt;class name="c1"&gt;
    &lt;view name="v2"/&gt;
    &lt;view name="v3"/&gt;
  &lt;/class&gt;
&lt;/library&gt;
</programlisting></example>
</section><section><title>Managing Memory</title>
<para>
In optimizing the performance of your application, it can be useful to look at the "memory footprint" of your application, and in particular, to see if that footprint grows over time.  (The way to determine memory usage by your application depends on the operating system on which it runs and is beyond the scope of this chapter.)
</para><para>
If memory usage for a given application tends to go up over time, you may have a "memory leak."  See <xref linkend="debugging"/> for an explanation of how to use the debugger to detect leakage.
</para>

<para/><section><title>Creating and Destroying Views</title>
<para>
In general, you do not have to worry about the resources consumed by creating views.  However,if you have an application that 
creates a large number of views, you may want to use the <indexterm><primary><literal>destroy()</literal></primary></indexterm><methodname>destroy()</methodname> to free 
memory.  
</para>
<para>
You would not need to use destroy if a view could only be referenced by one variable.  
Because views can be referenced in many ways (e.g., name, id, events, delegates, handlers) destroy can be used 
to 'detach' a view from all these links so that it can be garbage-collected.  destroy should not be needed in simple 
programs or programs that are built from Laszlo components.</para>
<para>
When tracking down memory usage, replicated views are a good place to look. When you make more than one copy of a view, you will use proportionally more memory.
So when performance tuning, remember that <literal>$path</literal> is implicated in replication.
</para>
<para>
Note that
constraints do not consume large amounts of memory.  
<literal>$once</literal> and <literal>$always</literal> are equivalent in memory usage, but clearly <literal>$always</literal> will require more CPU.

</para>
<para/></section></section><section><title>Hand-tuning constraints and attributes</title>
<para>
Once you get your program's functionality set, you can further optimize by "rebuilding in place."
</para>
<para/><section><title>Rewriting constraints</title>
<para>
Constraints are an extremely useful way to nicely lay out an application. They are conceptually elegant, allow for writing compact maintainable programs, and help with rapid application development. Constraints are so incredibly tasty for rapid prototyping. However, they can be expensive in terms of performance. 
</para>
<para>
The significant contributions to the cost of constraints aren't so much in the evaluation of the constraint expression itself.  Rather, they come about from two causes:</para>
<itemizedlist spacing="compact"><listitem><para>It's expensive to register a constraint.  Partly this is because each constraint requires two functions (which contributes to application size), and one function call (which contributes to startup time). </para></listitem><listitem><para>It's expensive to trigger a constraint, both because because there's one function call (it's the other function, this time), and because of the constraint machinery.</para></listitem></itemizedlist>
<para>
 Therefore it is sometimes helpful to replace constraints by explicitly setting attributes and chaining events with delegates. You should do this after the functionality of the program is essentially complete.
</para>
<para>Instead of writing</para>
<programlisting>
&lt;view id="foo" x="${parent.something}" y="${parent.something}"&gt;, 
</programlisting>
<para>
write the code that changes <literal>parent.something</literal> to update foo's x and y instead, replacing several function calls and loops through the constraint system by one function call. Too may constraints can make operations,
like resizing views and windows, pretty stuttery. Rethinking all those
constraints to minimize them and do some programatically by hand can really help in some cases.</para>
<para>
The <literal>$once</literal> technique also helps:
</para>
<programlisting>
&lt;view name="nugget" width="$once{thingy.width}" ... /&gt;
</programlisting>
<para>
 instead of
</para>
<programlisting>
&lt;view name="nugget" width="${thingy.width}" ... /
</programlisting>
<para>
This constraint is just evaluated once, when the view's attributes are first set. This will only work for static layouts, of course, and only if instantiation order works right. In this case, thingy must be constructed, and its width attribute must be set, and "thingy" must be in scope, in order for the $once form to work.
</para>
<para>
Another technique is to write your own "virtual constraints" in a method. This has the effect of reducing the number of method and function calls. The example below positions &lt;code&gt;dotty&lt;/code&gt; to sit inside &lt;code&gt;nugget&lt;/code&gt; with a padding of 5 pixels on the left and right.
</para>
<example role="live-example"><title>writing your own virtual constraints</title><programlisting>
&lt;view name="nugget"&gt;
&lt;view name="dotty" .... /&gt;
&lt;method name="init"&gt;
this.update();
super.init();
....
&lt;/method&gt;

&lt;method name="update"&gt;
this.setAttribute("width", thingy.width);
this.dotty.setX( 5 );
this.dotty.setAttribute( thingy.width - 10 );
...
&lt;/method&gt;

&lt;!-- Update positioning whenever thingy's width changes --&gt;
&lt;handler name="onwidth" target="thingy"&gt;
this.update();
&lt;/handler&gt;
....
&lt;/view&gt;
</programlisting></example>
<para>
Compare the above to:
</para>
<programlisting>
&lt;view name="nugget" width="${thingy.width}"&gt;
&lt;view name="dotty" x="5" width="${thingy.width - 10}"&gt;
...
&lt;/view&gt;
...
&lt;/view&gt;
</programlisting>
<para>
The second form is much more compact and readable, but the first form uses zero constraints. The call <literal>&lt;handler name="onwidth" target="thingy"&gt;</literal> is nearly a constraint on <literal>thingy.width</literal>, but: in the explicit-update form, one <literal>thingy.onwidth</literal> event can trigger a single call to update which, which will end up doing the repositioning that otherwise would require at least a handful of constraints. Like constraints, method calls are expensive. So, fewer constraints, fewer method calls, faster performance.</para>
<para/></section><section><title>Tuning attribute assignments</title>
<para>
You may, in some limited circumstances, gain a performance boost by assigning attribute values instead of setting them using a setter, (preferably, the <indexterm><primary><literal>setAttribute()</literal></primary></indexterm><methodname>setAttribute()</methodname> method). In general, using <literal>object.setAttribute('attr', value); </literal> to set an attribute is the best way to set attributes, as explained in <xref linkend="methods-events-attributes"/>. </para>
<para>
For speed, however, you may sometimes use a direct assignment, as in <literal>object.attr = value;</literal>.  When you do this, you need to be aware that no events are generated, and you are giving up the chance for any dependency that refers to <literal>object.attr</literal> to update. Use this technique with caution and only if you are sure that you have handled any dependencies. As we have heard said at Laszlo Systems, it's like overclocking your motherboard. You can do it if you think you know what you're doing, but don't blame us if your machine catches on fire. (Your machine won't literally catch on fire, of course, but your application may fail spectacularly!)
</para>

  <para/></section></section><section id="performance-tuning.compression"><title>Using compression to reduce size of DHTML downloads</title>
<para>
SWF files are internally gzip-compressed, which results in smaller files, especially when those files consist primarily of script, as do most OpenLaszlo-compiled applications. As a result, the smallest SWF-compiled OpenLaszlo application, which includes the LFC, is approximately 60K in size.
The comparable DHTML-complied OpenLaszlo application, in contrast, is approximately 250K. This would be a serious problem, except that gzip compression is supported as part of the HTTP standard, and can be enabled in various ways, including by settings on the Web server (Apache Web Server or similar) or, when the deployment includes the OpenLaszlo server, in the Java server environment. 
</para>
<para>
The effect of this compression, when correctly enabled in the serving environment, is that the compression is actually slightly better than the internal gzip compression supported by the SWF file format. Our measurements indicate that the 250K compresses down to 50K.
</para>
<para/><section><title>Server-side compression</title>
<para>
     The server-side configuration is different for different servlet containers and web servers. The idea is to tell whatever application responds to HTTP requests that it should compress JavaScript before sending it. We expect our users to deploy to a variety of servlet containers and web servers, so, instructions on how to configure a particular system to gzip JavaScript are beyond the scope of this document. We recommend that deployers do do this configuration. As an example, for tomcat, one would add attributes about compression to the connector tag in your server.xml:
</para>

<programlisting>
&lt;Connector port="8080"
compression="on"
compressionMinSize="2048"
noCompressionUserAgents="gozilla, traviata"
compressableMimeType="text/html,text/xml,text/JavaScript,application/x-JavaScript,application/JavaScript"/&gt;
</programlisting>
<para/></section><section><title>Client-side decompression</title>
<para>
The client-side configuration is much easier; <ulink url="http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html">the HTTP protocol specifies "content codings"</ulink> which may include <literal>gzip</literal>. A properly configured server will add the appropriate <literal>content-coding=gzip</literal> header, and modern browsers will recognize that that header means that the
content will be gzipped. With todays browsers (including all browsers supported by OL4), this does not require any client-side (browser) configuration.
    </para>
<para/></section></section></chapter>
